# The backend will exit after this many seconds of inactivity. This also
# limits how far in the future we can make guesses for slab preloading when
# the backend is idle. Because the backend will exit after this much idle time,
# the state of which slab was last loaded is lost. This should be greater
# than hint_slab_max_age_seconds or else we can't track hints long enough.
idle_timeout_seconds = 600

# The path for the hints database, containing information about the sequence
# in which slabs are typically loaded. This DB is used to make guesses and
# try to load slabs preemptively.
hints_database_path = "/var/potatofs_test/backend_s3_hints.db"

# When computing the time that passed between loading two slabs in a sequence,
# decrease the computed time by this many milliseconds. This way we can give
# us a bit of time to download the slab ahead of it being used, hopefully.
hint_skew_ms = 15000

# How many hints can be queued for preloading. This is mostly to keep memory
# usage under control and possibly avoid trying to preload too many things
# when a large chain of slab hints is triggered.
hints_preload_queue_size = 1000

# Maximum number of hints per slab. This is so we keep a cap on the database
# size and don't trigger more than this many preloads anytime to load a slab.
# Together with hint_slab_max_age_seconds, this is used to rate-limit how many
# hints we accept over time. We allow bursting up to 50% of that value, then
# the token bucket refills at one per
# hint_slab_max_age_seconds/(max_preload_per_hint/2) second.
#
# For each slab that this backend has seen, we can estimate the DB will grow
# by ~128 bytes. This means that, in the worst case where slabs are randomly
# loaded after any other slab, the DB could reach a size of:
# Nslabs * 128b * max_preload_per_hint.
#
# The database will never shrink on its own. The fixed record size also means
# vacuuming is unlikely to prove useful.
max_preload_per_hint = 50

# How many slabs to keep in memory for the purpose of updating their hints.
# Hints may be updated for this many slabs each time we get a get/hint request.
# Holding too many slabs in memory at once will use up more CPU and may cause
# lock contention on the hints table as we have to issue this many SQL updates
# each time.
hint_slabs_max_open = 50

# How long to keep track of open slabs. As long as a slab is consideredis
# in-memory, any new coming hint will be added to the "tree" of hints for
# preloading. In other words, preloading will be limited to sequences of slabs
# that are loaded at this interval, at most.
hint_slab_max_age_seconds = 120

s3_endpoint = "some.s3.endpoint"
s3_bucket = "some_bucket"
s3_region = "us-east-1"

# syslog mimimum log level. Priorities lower than this are silently discarded.
log_level = "notice"

# S3 credentials
access_key_id = "some id"
secret_access_key = "some key"

# Unix socket path to communicate with the background child that keeps
# our S3 session active.
socket_path = "/var/potatofs_test/.backend_s3.sock"

# Because this backend has infinite capacity, put a cap to it so we can
# correctly compute how much capacity our filesystem has. Here is 1TB.
backend_bytes = 1099511627776

# Timeout for S3 operations. Needs to be a bit longer than the
# potatofs backend timeout so we can properly receive the signal.
backend_timeout_seconds = 65

# Encryption/decryption key path
backend_secret_key_path = "/var/potatofs_test/secret"

# The command to preload slabs as predicted by the hints database. This should,
# for now, always point to the right "potatoctl -c <conf> claim <ino> <base>"
# command, optionally with the right config path. This is currently the only
# safe way to trigger a claim. The "%inode%" and "%base%" tokens will be
# replaced by the slab's inode/base that needs to be preloaded.
backend_claim_command = ""
